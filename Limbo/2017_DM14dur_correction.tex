\startcomponent component_DS1
\project project_Res_Mathematica
\environment environment_Maths
\environment environment_Inferno
\xmlprocessfile{exo}{xml/Limbo_Exercices.xml}{}
\iffalse
\setupitemgroup[List][1][R,inmargin][after=,before=,left={\bf Exo },symstyle=bold,inbetween={\blank[big]}]
\setupitemgroup[List][2][n,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][3][a,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][4][1,joineup,nowhite]
\fi

%\setupitemgroup[List][1][A,inmargin][after=,before=,left={\bf Exo },symstyle=bold,inbetween={\blank[big]}]
%\setupitemgroup[List][1][R,joineup][after=,before=,inbetween={\blank[small]}]
%\setupitemgroup[List][1][n,inmargin][after=,before=,left={\bf Exo },symstyle=bold,inbetween={\%blank[big]}]
%\setupitemgroup[List][2][n,joineup][after=,before=,inbetween={\blank[small]}]
%\setupitemgroup[List][3][a,joineup][after=,before=,inbetween={\blank[small]}]
%\setupitemgroup[List][4][1,joineup,nowhite]
%\setupitemgroup[List][4][a,joineup,nowhite]
\definecolor[myGreen][r=0.55, g=0.76, b=0.29]%
\setuppapersize[A4]
\setuppagenumbering[location=]
\setuplayout[header=0pt,footer=0pt]
\def\conseil#1{{\myGreen\it #1}}%


\starttext
\setupheads[alternative=middle]
%\showlayout
\def\gah#1{\margintext{Exercice #1}}

\iftrue
\page
\centerline{\bfb DEVOIR MAISON 14}
\blank[big]

\setupitemgroup[List][1][A,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][2][n,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][3][a,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][4][1,joineup,nowhite]


\centerline{\bf CORRECTION DU PROBLÃˆME 1}
\blank[big]
\startList%
\item%1 GÃ©nÃ©ralitÃ©s
\startList
\item%a

\startitemize[1]
\item $\mc C_A$ est inclus, par dÃ©finition, dans $\mc M_n(â„)$, qui est un $â„$-espace vectoriel de rÃ©fÃ©rence 
\item $\mc C_A$ contient la matrice nulle car $AÃ—0=0=0Ã—A$ de sorte que $\mc C_Aâ‰ \emptyset$
\item Soient $(Î»,Î¼)âˆˆâ„^2$ et $(M,N)âˆˆ\mc C_A^2$. Comme $AM=MA$ et $AN=NA$, il rÃ©sulte de la distributivitÃ© du produit matriciel et de la loi du scalaire mobile que  
\startformula
(Î»M+Î¼N)Ã—A=Î»MA+Î¼NA=Î»AM+Î¼AN=(Î»M+Î¼N)Ã—A
\stopformula
En particulier, $Î»M+Î¼Nâˆˆ\mc C_A$. L'ensemble $\mc C_A$ est donc stable par combinaison linÃ©aire.
\stopitemize
En conclusion, $\mc C_A$ est un sous-espace vectoriel de $\mc M_n(â„)$. 
\item%b
Pour $Mâˆˆ\mc M_n(â„)$, et $Î»âˆˆâ„$, il rÃ©sulte de l'associativitÃ© du produit, de la loi du scalaire mobile et du fait que $I_n$ soit un Ã©lÃ©ment neutrte pour la multiplication, que 
\startformula
MÃ—(Î»I_n)=Î»(MÃ—I_n)=Î»M=Î»(I_nÃ—M)=(Î»I_n)Ã—M
\stopformula
En particulier $Mâˆˆ\mc C_{Î»I_n}$, de sorte que 
\startformula
\mc C_{Î»I_n}=\mc M_n(â„)\qquad(Î»âˆˆâ„).
\stopformula
\item Soit $Aâˆˆ\mc M_n(â„)$. Si $Aâˆˆ\Vect(I_n)$, il rÃ©sulte des calculs effectuÃ©s dans la question prÃ©cÃ©dente que 
$\dim(\mc C_A)=\dim\big(\mc M_n(â„)\big)=n^2â©¾2$.

Si $A\âˆ‰\Vect(I_n)$, alors $\mc C_A$ est un sous-espace vectoriel de $\mc M_n(â„)$, contenant les matrices $I_n$ (car $AÃ—I_n=A=I_nÃ—A$) et $A$ (car $AÃ—A=A^2=AÃ—A$). 
Comme la famille $\{I_n,A\}$ est libre (puisque $Aâˆ‰\Vect(I_n)$), $\mc C_A$ est de dimension au moins $2$ car il contient une famille libre de deux vecteurs.
\crlf
Dans tous les cas, $\mc C_A$ est au moins de dimension $2$.
\item {\it Houla, c'est une question technique Ã§a... qui exploite le fait que les bases permettent de transformer (via isomorphisme) vecteurs en coordonnÃ©es, applications linÃ©aires en matrices, etc...}
Soit $\Fun{Ïˆ:\mc L(â„^n)â†’M_n(â„)|fâ†¦\mc Mat_â„¬(f)}$ l'isomorphisme (d'aprÃ¨s le cours) associant Ã  un endomorphisme $f$ de $â„^n$, sa matrice dans la base $â„¬$.
Alors, je prÃ©tends que $Ïˆ$ transforme $\mc C_f$ en $\mc C_A$, c'est Ã  dire que $Ïˆ(\mc C_f)=\mc C_A$, ce qui implique (les deux espaces Ã©tant isomorphes) que 
\startformula
\dim(\mc C_f)=\dim(\mc C_A)
\stopformula
En effet, comme $A= \mc Mat_â„¬(f)=Ïˆ(f)$, pour $fâˆˆâ„’(â„^n)$, nous remarquons que 
\startformula
\Align{
\NC gâˆˆ\mc C_f\NC âŸº fâˆ˜g=gâˆ˜fâŸº\mc Mat_â„¬(fâˆ˜g)=\mc Mat_â„¬(gâˆ˜f)\NR
\NC \NC âŸº\mc Mat_â„¬(f)Ã—\mc Mat_â„¬(g)=\mc Mat_â„¬(g)Ã—\mc Mat_â„¬(f)\NR
\NC \NC âŸº\mc AÃ—\mc Mat_â„¬(g)=\mc Mat_â„¬(g)Ã—A\NR
\NC\NC âŸº\mc Mat_â„¬(g)âˆˆ\mc C_A\NR
\NC\NC âŸº Ïˆ(g)âˆˆ\mc C_A
}
\stopformula
A fortiori, on a bien $Ïˆ(\mc C_f)=Ïˆ(\mc C_A)$.
\item {\it du Scilab !}\crlf
\starttyping
function [r]=commutables(A,B)
   r = A*B == B*A
endfunction
\stoptyping
\stopList
\item%2
\startList
\item%a
{\it On peut utiliser la mÃ©thode MARRE mais on va faire ici plus court/Ã©lÃ©gant via des Ã©quivalences}\crlf
Pour $Mâˆˆ\mc M_n(â„)$, nous remarquons que 
\startformula
\Align{
\NC Mâˆˆ\mc C_B\NC âŸºMÃ—B=BÃ—MâŸºM\Q(A-{\text{tr}(A)\F 2}I_2\W)=\Q(A-{\text{tr}(A)\F 2}I_2\W)M\NR
\NC\NC MA-{\text{tr}(A)\F 2}M=AM-{\text{tr}(A)\F 2}âŸºMA=AM\NR
\NC\NC âŸºMâˆˆ\mc C_A
}
\stopformula
En particulier, nous avons $\mc C_B=\mc C_A$. 
\item Nous remarquon que 
\startformula
B=\Matrix{
\NC {a-d\F 2}\NC b\NR
\NC c\NC {d-a\F 2}}\qquad B^2=\Matrix{
\NC \Q({a-d\F 2}\W)^2+bc\NC {a-d\F 2}b+b{d-a\F 2}\NR
\NC c{a-d\F 2}+{d-a\F 2}c\NC bc+\Q({d-a\F 2}\W)^2
}=\Q(bc+\Q({d-a\F 2}\W)^2\W)I_2
\stopformula
En particulier, pour $r=bc+\Q({d-a\F 2}\W)^2$ et $P=x^2-rI_2$, nous avons 
\startformula
P(B)=B^2-rI_2=0
\stopformula
De sorte que $P$ est un polynÃ´me annulateur de $B$.
\item Soient $râˆˆâ„$ et $N=\Matrix{\NC a\NC b\NR \NC c\NC d}âˆˆ\mc M_2(â„)$. alors, on a 
\startformula
\Align{[align={right, left,left}]
\NC Nâˆˆ\mc C_M\NC âŸº\NC NM=MNâŸº\Matrix{\NC a\NC b\NR\NC c\NC d}Ã—\Matrix{\NC 0\NC r\NR\NC 1\NC 0}=\Matrix{\NC 0\NC r\NR\NC 1\NC 0}Ã—\Matrix{\NC a\NC b\NR\NC c\NC d}\NR
\NC \NC âŸº\NC \Matrix{
\NC b\NC ar\NR\NC d\NC cr}=\Matrix{
\NC rc\NC rd\NR \NC a\NC b}\NR
\NC \NC Â âŸº\NC \System{
\NC b=rc\NR
\NC ar=rd\NR
\NC d=a\NR
\NC cr=b
}\NR
\NC\NC âŸº\NC \System{
\NC b=rc\NR
\NC d=a
}
}
\stopformula
A fortiori, on a
\startformula
\mc C_M=\Q\{aI_2+c\Matrix{\NC 0\NC r\NR\NC 1\NC 0}:(a,c)âˆˆâ„^2\W\}=\Vect\Q(I_2, \Matrix{\NC 0\NC r\NR\NC 1\NC 0}\W)
\stopformula
De sorte que $\mc C_M$ est de dimension $2$ quel que soit $râˆˆâ„$
\item {\it Question bizarrement posÃ©e. Il faut lire la question suivante pour voir oÃ¹ ils veulent en venir... }\crlf
Supposons que les trois familles de deux vecteurs $(e_1,f(e_1)$, $(e_2, f(e_2))$ et $(e_1+e_2, f(e_1+e_2))$ soient liÃ©es. 
Comme $e_1$, $e_2$ et $e_1+e_2$ sont des vecteurs non nuls, il existe $(a,b,c)âˆˆâ„^3\ssm\{(0,0,0)\}$ tels que 
\startformula
\System{
\NC f(e_1)=ae_1\NR
\NC f(e_2) = be_2\NR
\NC f(e_1+e_2)=c(e_1+e_2)
}
âŸ¹ 0=f(e_1+e_2)-f(e_1)-f(e_2)=(c-a)e_1+(c-b)e_2=0
\stopformula
Comme $(e_1,e_2$ est libre (puisque c'est une base), nous avons forcÃ©ment $c-a=0=c-b$, de sorte que $a=c=b$.
Nous en dÃ©duisons alors que $f(e_1)=ae_1=a\text{Id}(e_1)$ et $f(e_2)=be_2=ae_2=a\text{Id}(e_2)$.
Comme les applications linÃ©aires $f$ et $a\text{Id}$ coincident sur la base $(e_1,e_2)$, elles sont Ã©gales, de sorte que 
\startformula
f=a\text{Id}
\stopformula
Ceci contredit la dÃ©finition de $f$, car la matrice canoniquement associÃ©e Ã  $f$ est $B=A-{\text{tr}(A)\F 2}I_2â‰ aI_2$, en effet $(A, I_2)$ est libre
\item Il rÃ©sulte du raisonnement par l'absurde  menÃ© Ã  la question prÃ©cÃ©dente qu'il existe un vecteur $vâˆˆâ„^2$ tel que $(v, f(v))$ soit libre car les trois familles 
$(e_1, f(e_1)$, $(e_2, f(e_2))$ et $(e_1+e_2, f(e_1+e_2))$ ne peuvent pas Ãªtre toutes liÃ©es. 
A fortiori, la famille libre $ğ““=(v, f(v))$ de deux vecteurs de $â„^2$, en constitue une base. \crlf
{\it Accrochez vous !}\crlf
Comme $X^2-r$ est un polynÃ´me annulateur de $B$, c'est Ã©galement un polynÃ´me annulateur de $f$, de sorte que
$f^2-r\text{Id}=0$. 

En particulier, $f^2(v)=r\text{Id}(v)=rv$. De sorte que 
\startformula
\mc Mat_ğ““(f)=\Matrix{\NC 0\NC r\NR
\NC 1\NC 0}=M
\stopformula
\item {\it Faisons la synthÃ¨se des questions prÃ©cÃ©dentes}
Il rÃ©sulte de la question 2a que $\dim(\mc C_A)=\dim(\mc B)$. Or d'aprÃ¨s la question 1d, il vient 
$\dim(\mc C_B)=\dim(\mc C_f)$. Or dans la base $ğ““$, $\mc Mat_ğ““(f)=M$, de sorte que l'on peut montrer que 
$\dim(\mc C_f)=\dim(\mc C_M)$ {\it (un peu comme Ã  la question 1d, sauf qu'au lieu d'utiliser la base canonique, on utilise la base $ğ““$)}
Et enfin, il rÃ©sulte de la question 2c que $\dim(\mc C_M)=2$ de sorte que $\dim(\mc C_A)=2$. Comme $(A, I_2)$ est une famille libre de $\mc C_A$, c'en est une base.
{\it Une maniÃ¨re bien torturÃ©e d'arrivr Ã  ce rÃ©sultat, dans un cas relativement simple...la dimension $2$}
\stopList
\item%3
\startList
\item%a
{\it On remarque au brouillon que $C_1-C_2=0$ et que $C_1-C_3=0$...}
Les vecteurs $(1,-1,0)$ et $(1,0,-1)$ appartiennent au noyau de $f$ car
\startformula
AÃ—\Matrix{
\NC 1\NR
\NC -1\NR
\NC 0} = \Matrix{
\NC 1-1+0\NR
\NC -1+1+0\NR
\NC 1-1+0
}=0\Et AÃ—\Matrix{
\NC 1\NR
\NC 0\NR
\NC -1} = \Matrix{
\NC 1+0-1\NR
\NC -1+0+1\NR
\NC 1+0-1
}=0
\stopformula
Comme $A$ est clairement de rang $1$, il rÃ©sulte du thÃ¨orÃ¨me du rang que $\dim(\ker f)=\dim(â„^3)-\rg(f)=3-1-2$ de sorte que 
\startformula
\ker(f)=\Vect\big((1,-1,0),(1,0,-1)\big)
\stopformula
Ensuite, l'image de $f$ qui est de dimension $1$, est $\IM(f)=\Vect(f(1,0,0))=\Vect\big((1,-1,1)\big)$.
{\it le sujet demande l'image et le noyau de $a$, un lÃ©ger abus, il derait demander le noyau et l'image de l'endomorphisme $f$ associÃ© Ã  $A$ dans la base canonique}
\item On remarque que $A^2=\Matrix{
\NC 1-1+1\NC 1-1+1\NC 1-1+1\NR
\NC -1+1-1\NC -1+1-1\NC -1+1-1\NR
\NC 1-1+1\NC 1-1+1\NC 1-1+1}=A$. 

A fortiori, $A$ est la matrice d'un projecteur, donc $f$ est un projecteur.
L'endomorphisme $f$ est donc une projection sur son image $\IM (f)$ dÃ©terminÃ©e prÃ©cÃ©demment, parallÃ©lement Ã  son noyau, dÃ©terminÃ©e prÃ©cÃ©demment Ã©galement.
\item $P$ est inversible car c'est une matrice de $\mc M_3(â„)$ de rang $3$. En effet
\startformula
\rg(P)=\rg\Matrix{
\NC 2\NC 1\NC 0\NR
\NC -1\NC -1\NC 0\NR
\NC 1\NC 0\NC -1}=\rg\Matrix{
\NC 2\NC 1\NC 0\NR
\NC -1\NC -1\NC 0\NR
\NC 0\NC 0\NC -1}=\rg\Matrix{
\NC 1\NC 0\NC 0\NR
\NC -1\NC -1\NC 0\NR
\NC 0\NC 0\NC -1}=3
\stopformula
{\it J'aurais mieux fait d'inverser directement $P$, vu qu'on a aussi besoin de l'inverse...}
En dÃ©duisons que la matrice $P$ est inversible, d'inverse 
\startformula
P^{-1}=Q=\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
},
\stopformula
du calcul
\startformula
QÃ—P=
\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
}Ã—\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -1\NC 0\NR
\NC 1\NC 0\NC -1
}=\Matrix{
\NC 1-1+1\NC 1-1\NC 1-1\NR
\NC -1+2-1\NC -1+2\NC -1+1\NR
\NC 1-1\NC 1-1\NC 1
}=I_3.
\stopformula
 {\it J'ai fait la recherche de matrice inverse au brouillon bien sÃ»r, avec l'algorithme standard}

 \item $Î¦$ est un automorphisme de $\mc M_n(â„)$ car c'est un endomorphisme de $\mc M_n(â„)$
 \startitemize[1]
\item  $\mc M_n(â„)$ est un $â„$-espace vectoriel (au dÃ©part et Ã  l'arrivÃ©e)
\item Pour $Mâˆˆ \mc M_n(â„)$, $PÃ—MÃ—P^{-1}$ est dÃ©finit et appartient Ã  $\mc M_n(â„)$ en tant que produit de matrices rÃ©elles carrÃ©es de taille $n$.
De sorte que $Î¦:\mc M_n(â„)â†’\mc M_n(â„)$ est une application
\item Soient $(Î»,Î¼)âˆˆâ„Â²$ et $(M,N)âˆˆ\mc M_n(â„)^2$, il rÃ©sulte de la distributivitÃ© et de la loi du scalaire mobile que  
\startformula
\Align{
\NC Î¦(Î»M+Î¼N)\NC =P(Î»M+Î¼N)P^{-1}=P(Î»M)P^{-1}+P(Î¼N)P^{-1}\NR
\NC\NC =Î»PMP^{-1}+Î¼PNP^{-1}\NR
\NC\NC=Î»Î¦(M)=+Î¼Î¦(N)
}
\stopformula
\stopitemize
De plus, le noyau de $Î¦$ est rÃ©duit Ã  la matrice nulle car (en multipliant par $P$ Ã  droite et $P^{-1}$ Ã  gauche)
\startformula
Mâˆˆ\ker(Î¦)âŸºÎ¦(M)=0âŸºPMP^{-1}=0âŸºPM=0Ã—P=0âŸºM=P^{-1}Ã—0=0
\stopformula
A fortiori, $Î¦$ est injective et mÃªme (espace vectoriel de mÃªme dimension finie au dÃ©part et Ã  l'arrivÃ©e) bijective
C'est doncun automorphisme de $\mc M_n(â„)$. 
Enfin, pour une matrice $M$ de $\mc M_n(â„)$, nous remarquons que $Î¦^{-1}(M)=P^{-1}MP$ et aussi que (multiplication par $P^{-1}$ Ã  gauche et par $P$ Ã  droite)
\startformula
\Align{
\NC Mâˆˆ\mc C_{PAP^{-1}}\NC âŸºMÃ—PAP^{-1}=PAP^{-1}Ã—M\NR
\NC\NC âŸºP^{-1}MÃ—PAP^{-1}=AP^{-1}Ã—M\NR
\NC\NC âŸºP^{-1}MÃ—PA=AP^{-1}Ã—MÃ—P\NR
\NC\NC âŸºP^{-1}MPÃ—A=AÃ—P^{-1}MP\NR
\NC\NC âŸºÎ¦^{-1}(M)Ã—A=AÃ—Î¦^{-1}(M)\NR
\NC\NC âŸº Î¦^{-1}(M)âˆˆ\mc C_A\NR
\NC\NC âŸº MâˆˆÎ¦(\mc C_A)\NR
}
\stopformula
A fortiori, nous obtenons que $Î¦(\mc C_A)=C_{PAP^{-1}}=C_{Î¦(A}$
\item Nous remarquons que 
\startformula
\Align{
\NC PAP^{-1}\NC =PAQ=\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
}Ã—\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -1\NC -1\NR
\NC 1\NC 1\NC 1
}Ã—\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
}\NR
\NC\NC =\Matrix{
\NC 1\NC 1\NC 1\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0
}Ã—\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
}=\Matrix{
\NC 1\NC 0\NC 0\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0
}=DÂ }
\stopformula

{\it Pour info, nous venons de diagonaliser la matrice $A$ (algorithme ECS2), c'est sensÃ© simplifier le probleme car $D$ est plus simple que $A$}
Etant donnÃ©e une matrice $M=\Matrix{
\NC a\NC b\NC c\NR
\NC d\NC e\NC f\NR
\NC g\NC g\NC i
}$, nous avons
\startformula
\Align{
\NC Mâˆˆ\mc C_D\NC âŸºMD=DMâŸº\Matrix{
\NC a \NC 0\NC 0\NR
\NC d\NC 0\NC 0\NR
\NC g\NC 0\NC 0}=\Matrix{
\NC a\NC b\NC c\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0\NR
}\NR
\NC \NC âŸº M = \Matrix{
\NC a\NC 0\NC 0\NR
\NC 0\NC e\NC f\NR
\NC 0\NC g\NC i
}
}
\stopformula
De sorte que $\mc C_D=\mc C_{PAP^{-1}}=\Vect\Q(D, \Matrix{
\NC 0\NC 0\NC 0\NR
\NC 0\NC 1\NC 0\NR
\NC 0\NC 0\NC 0
},  \Matrix{
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 1\NR
\NC 0\NC 0\NC 0
},  \Matrix{
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 1\NC 0
},  \Matrix{
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 1
}\W)$
et que $\dim(\mc C_A)=\dim(Î¦(\mc C_A))\dim(\mc C_D)=5$
{\it Wahh, c'est bourrin quand mÃªme...}
\stopList
\item \startList
\item Comme $p$ est un projecteur de $â„^n$, on sait que
\startformula
â„^n=\ker p âŠ• \IM p
\stopformula
Comme $p$ est de rang $p$, la dimension de son image est $p$.
Soit $e_1,â€¦,e_p$ une base de son image et $e_{p+1}, â€¦,e_n$ une base de son noyau (qui est de dimension $n-p$, d'aprÃ¨s l'identitÃ© ci-dessus).
Alors, d'aprÃ¨s la propriÃ©tÃ© de concatÃ©nation des bases, $â„¬=(e_1, â€¦, e_n)$ est une base de $â„^n$ et comme les vecteurs de l'image de $p$ sont  invariants par $p$ 
alors que les vecteurs du noyau de $p$ sont transformÃ©s en $0$, on a 
\startformula
\mc Mat_{â„¬}(p)=\Matrix{
\NC 1\NC 0\NC â‹¯\NC â‹¯\NC â‹¯\NC 0\NR
\NC 0\NC â‹±\NCâ‹± \NC\NC \NCâ‹®\NR
\NCâ‹®\NC â‹± \NC 1\NC â‹±\NC \NCâ‹®\NR
\NCâ‹®\NC  \NC â‹±\NC 0\NC â‹± \NCâ‹®\NR
\NCâ‹®\NC  \NC \NC â‹±\NC â‹± \NCâ‹®\NR
\NC 0\NC â‹¯ \NC â‹¯\NC â‹¯\NC â‹¯ \NC 0
}=\Matrix{\NC I_r\NC 0\NR\NC 0\NC 0}=J_r,
\stopformula
La matrice ci dessus contenant $r$ $1$ sur la diagonale principale
\item $f$ appartient Ã  $\mc C_p$ si et seulement si $f$ commute avec $p$. ProcÃ©dons {\it avec la mÃ©thode MARRE} par double implication.
Supposons que $p$ commute avec $f$. Alors, pour $xâˆˆ\ker(p)$, on a
\startformula
p\big(f(x)\big)=pâˆ˜f(x)=fâˆ˜p(x)=f\big(p(x)\big)=f(0)=0
\stopformula
De sorte que $p(x)âˆˆ\ker(p)$. Le noyau de $p$ est donc stable par $f$.
Par ailleurs, si $yâˆˆ\IM(p)$, alors il existe $xâˆˆâ„^n$ tel que $y=p(x)$ et alors
\startformula
f(y)=f\big(p(x)\big)=fâˆ˜p(x)=pâˆ˜f(x)=p\big(f(x)\big)âˆˆ\IM(p)
\stopformula
De sorte que l'image de $p$ est Ã©galement stable par $f$. \crlf
RÃ©ciproquement, supposons que le noyau et l'image de $p$ soit stable par $f$.
Soit $xâˆˆâ„^n$. Comme $â„^n=\ker p âŠ• \IM p$, il existe un vecteur $yâˆˆ\IM(p)$ (et donc $y=p(y)$) et un vecteur $zâˆˆ\ker(p)$ (et donc $p(z)=0$) tels que $x=y+z$.
A fortiori, commeles vecteurs de l'image de $p$ sont invariants par $p$, il vient 
\startformula
\Align{
\NC fâˆ˜p(x)\NC =f\big(p(x)\big)=f\big(p(y+z)\big)=f\big(p(y)+p(z)\big)=f\big(y+0\big)\NR
\NC \NC =\underbrace{f(y)}_{âˆˆ\IM(p)}=p\big(f(y)\big) + 0=p\big(f(y)\big)+p\big(\underbrace{f(z)}_{âˆˆ\ker(p)}\big)\NR
\NC\NC =p\big(f(y+z)\big)=p\big(f(x)\big)\NR
\NC\NC=pâˆ˜f(x)
}
\stopformula
En particulier, les applications $fâˆ˜p$ et $pâˆ˜f$ coincident sur $â„^n$, donc elles sont Ã©gales. De sorte que $pâˆ˜f=fâˆ˜p$, c'est Ã  dire qu'elles commutent.
{\it Ouch, dur...}
\item La matrice de $fâˆˆ\mc C_p$ dans la base de la question a doit avoir la forme $\Matrix{\NC M_r\NC 0\NR\NC 0\NC N_{n-r}}$, 
avec $M_r$ matrice carrÃ©e quelconque de taille $r$ et $N_{n-r}$ matrice carrÃ©e quelconque de taille $n-r$, 
Car le noyau et l'images de $p$ doivent Ãªtre stables par $f$, 
{\it $M_r$ est la matrice de la restriction de $f$ Ã  $\IM(p)$ et $N_{n-r}$ est la matrice de la restriction de $f$ Ã  $\ker(p)$}
\item En particulier, comme $\mc C_p$ est l'ensemble des applications $f$ dont la matrice (dans la base de a) vÃ©rifie les contraintes Ã©noncÃ©es dans la question prÃ©cÃ©dentes, on a 
\startformula
\dim(\mc C_p) = r^2+(n-r)^2
\stopformula
\item $M$ est la matrice d'un projecteur $p$ de rang $r=\rg(M)$. A fortiori, on a 
\startformula
\dim(\mc C_M)= \dim(\mc C_p) = r^2+(n-r)^2=\rg(M)^2+\big(n-\rg(M)\big)^2
\stopformula
\stopList


\centerline{\bf Correction du ProblÃ¨me 2}

{\bf 0.} Comme $\displaystyle\lim_{nâ†’+âˆ}\arctan(n)=+{Ï€\F 2}$, comme $\displaystyle\lim_{nâ†’âˆ}{\sin n\F n}=0$ et comme 
\startformula
n\sin{1\F n}âˆ¼nÃ—{1\F n}=1â†’1,
\stopformula
il vient
\startformula
\lim_{nâ†’+âˆ}M_n=\Matrix{\NC {Ï€\F 2}\NC 0\NR\NC 1\NC 3}
\stopformula
\startList
\item Soit $nâˆˆâ„•$. Slors, nous dÃ©duisons du changement d'indice $i'=i-r$ et de la $r$-pÃ©riodicitÃ© de la suite $x$ que
\startformula
\Align{
\NC \displaystyle{1\F r}âˆ‘_{i=n}^{n+r-1}x_i-y\NC\displaystyle={1\F r}âˆ‘_{i=n}^{n+r-1}x_i-{1\F r}âˆ‘_{i=0}^{r-1}x_i\NR
\NC \NC \displaystyle= {1\F r}\Q(âˆ‘_{i=r}^{n+r-1}x_i-âˆ‘_{i=0}^{n-1}x_i\W)\NR
\NC\NC \displaystyle= {1\F r}\Q(âˆ‘_{i'=0}^{n-1}x_{i'+r}-âˆ‘_{i=0}^{n-1}x_i\W)\NR
\NC\NC \displaystyle= {1\F r}\Q(âˆ‘_{i'=0}^{n-1}x_{i'}-âˆ‘_{i=0}^{n-1}x_i\W)=0\NR
}
\stopformula
En particulier, nous obtenons que $\displaystyle y={1\F r}âˆ‘_{i=n}^{n+r-1}x_i$ pour $nâˆˆâ„•$.
\item Pour $nâ©¾1$, nous remarquons que 
\startformula
\Align{
\NC w_{n+r}\NC =\displaystyle (n+r)y_{n+r}-(n+r)y=(n+r){1\F n+r}âˆ‘_{i=0}^{n+r-1}x_i-(n+r)y\NR
\NC \NC \displaystyle= âˆ‘_{i=0}^{n+r-1}x_i-(n+r)y\NR
\NC \NC \displaystyle= âˆ‘_{i=0}^{n-1}x_i + âˆ‘_{i=n}^{n+r-1}x_i-(n+r)y\NR
\NC \NC \displaystyle= ny_n + \underbrace{âˆ‘_{i=n}^{n+r-1}x_i}_{ry}-(n+r)y\NR
\NC \NC = ny_n -ny=w_n
}
\stopformula
En particulier, la suite $(w_n)_{nâ©¾1}$ est $r$-pÃ©riodique.
\item Une suite $r$-pÃ©riodique $(x_n)_{nâ©¾0}$ est bornÃ©e car 
\startformula
|x_k|â©½M=\max\big\{|x_0|, â‹¯, |x_{r-1}|\big\}\qquad(kâ©¾0)
\stopformula
En effet, pour $kâˆˆâ„•$, il rÃ©sulte de la division euclidienne de $k$ par $r$ qu'il existe deux entiers $qâ©¾0$ et $sâˆˆâŸ¦0,r-1âŸ§$ tel que $k=qr+s$ et alors, on a 
\startformula
|x_k|=|x_{qr+s}|=|w_s|â©½M
\stopformula
\item Comme la suite $w$ est $r$-pÃ©riodique, elle est bornÃ©e, de sorte qu'il existe un nombre rÃ©el $M$ vÃ©rifiant $|w_n|â©½M$ pour $nâ©¾1$.
Alors, nous obtenons que 
\startformula
|y_n-y|=\Q|{w_n\F n}\W|={|w_n|\F n}â©½{M\F n}\qquad (nâ©¾1).
\stopformula
Comme $\displaystyle\lim_{nâ†’+âˆ}{M\F n}=0$, il rÃ©sulte de la propriÃ©tÃ© des gendarmes que 
\startformula
\displaystyle\lim_{nâ†’+âˆ}(y_n-y)=0
\stopformula
et donc que $\displaystyle\lim_{nâ†’+âˆ}y_n=y$.
\stopList
\item \startList
\item Nous remarquons que 
\startformula
\System{
\NC B-{1\F 6}C=A\NR
\NC B+C=I_2}âŸº\System{
\NC B-{1\F 6}C=A\NR
\NC {7\F 6}C=I_2-A}âŸº
\System{
\NC B=A+{1\F 7}(I_2-A)={1\F 7}(I_2+6A)={1\F 7}\Matrix{\NC 3\NC 4\NR \NC 3\NC 4}\NR
\NC C={6\F 7}(I_2-A)={6\F 7}\Matrix{\NC {2\F 3}\NC {-2\F 3}\NR \NC{-1/2}\NC {1\F 2}}
={1\F 7}\Matrix{\NC 4\NC -4\NR \NC -3\NC 3}
}
\stopformula
\item De simples calculs matriciels donnent
\startformula
\Align{
\NC B^2\NC ={1\F 7^2}\Matrix{\NC 21\NC 28\NR \NC 21\NC 28}={1\F 7}\Matrix{\NC 3\NC 4\NR \NC 3\NC 4}=B\NR
\NC C^2\NC ={1\F 7^2}\Matrix{\NC 28\NC -28\NR \NC -21\NC 21}={1\F 7}\Matrix{\NC 4\NC -4\NR \NC -3\NC 3}=C\NR
\NC BC\NC ={1\F 7^2}\Matrix{\NC 12-12\NC -12+12\NR \NC 12-12\NC -12+12}=0\NR
\NC CB\NC ={1\F 7^2}\Matrix{\NC 12-12\NC 16-16\NR \NC -9+9\NC -12+12}=0\NR
}
\stopformula
En particulier, $B$ et $C$ sont des matrices de projecteurs qui commutent.
\item Pour $nâ©¾1$, il rÃ©sulte alors du binÃ´me de Newton ($B$ et $C$ commutent) que
\startformula
\Align{
\NC A^n\NC \displaystyle=\Q(B-{1\F 6}C\W)^n=âˆ‘_{k=0}^n{n\choose k}\Q(-{1\F 6}C\W)^kB^{n-k}\NR
\NC\NC \displaystyle=B^n+\Q(-{1\F 6}C\W)^n+âˆ‘_{k=1}^{n-1}{n\choose k}\Q(-{1\F 6}C\W)^kB^{n-k}\NR
\NC\NC \displaystyle=B+\Q(-{1\F 6}\W)^nC+âˆ‘_{k=1}^{n-1}{n\choose k}\Q(-{1\F 6}\W)^k\underbrace{CB}_{0}\NR
\NC\NC \displaystyle=B+\Q(-{1\F 6}\W)^nC
}
\stopformula
En particulier, nous obtenons que $A^n=B+\Q(-{1\F 6}\W)^nCâˆˆ\Vect(B,C)$
\item Il rÃ©sulte du calcul prÃ©cÃ©dent que $\lim_{nâ†’+âˆ}A^n=B$. Par ailleurs, nous dÃ©duisons de la formule des sommes gÃ©omÃ©triques que 
\startformula
\Align{
\NC P_n(A)\NC \displaystyle={1\F n}âˆ‘_{k=0}^{n-1}A^k={1\F n}\Q(I_2+âˆ‘_{k=1}^{n-1}\Q(B+\Q(-{1\F 6}\W)^kC\W)\W)\NR
\NC\NC \displaystyle={1\F n}\Q(I_2+(n-1)B+ \Q(âˆ‘_{k=1}^{n-1}\Q(-{1\F 6}\W)^k\W)C\W)\NR
\NC\NC \displaystyle={1\F n}\Q(I_2+(n-1)B+ {-{1\F 6}-\Q(-{1\F 6}\W)^n\F 1+{1\F 6}}C\W)
}
\stopformula
En particulier, nous obtenons que $\displaystyle\lim_{nâ†’+âˆ}P_n(A)=B$
\stopList
\item\startList
\item Nous remarquons que 
\startformula
M^2=\Matrix{
\NC 0\NC 0\NC 1\NR
\NC 1\NC -3\NC 3\NR
\NC 3\NC -8\NC 6}\qquad\Et\qquad 
M^3=\Matrix{
\NC 1\NC -3\NC 3\NR
\NC 3\NC -8\NC 6\NR
\NC 6\NC -15\NC 10}
\stopformula
Alors, nous remarquons que 
\startformula
M^3-3M^2+3M-I_3=\Matrix{
\NC 1-1\NC -3+3\NC 3-3\NR
\NC 3-3\NC -8+9-1\NC 6-9+3\NR
\NC 6-9+3\NC -15+24-9\NC 10-18+9-1}=0
\stopformula
de sorte que le polynÃ´me unitaire $P=X^3-3X^2+3X-1$ est un polynÃ´me annulateur de $M$. 
\item ProcÃ©dons Ã  la division euclidienne (thÃ©orique) de $X^n$ par $P$. Alors, il existe deux polynÃ´mes $Qâˆˆâ„[X]$ et $PâˆˆR_2[X]$ uniques tels que $X^n=PQ+R$.
{\it On veut surtout le reste de la division en fait...}

Comme $P=X^3-3X^2+3X-1=(X-1)^3$, en substituant $1$ Ã  $X$ puis en dÃ©rivant et en substituant $1$ Ã  $X$, puis en dÃ©rivant $2$ fois et en substituant $1$ Ã  $X$ dans 
\startformula
X^n=PQ+R=(X-1)^3Q+a+bX+cX^2,
\stopformula
il vient
\startformula
\System{
\NC a+b+c = 1\NR
\NC b+2c = n\NR
\NC 2c = n(n-1)
}âŸº \System{
\NC c={n(n-1)\F 2}\NR
\NC b=n-n(n-1)=n(2-n)\NR
\NC a=1-b-c=1-{n(n-1)\F 2}-n(2-n)={n^2-3n+2\F 2}
}
\stopformula

En notant $R=a+bX+cX^2$ et en substituant $M$ Ã  $X$ il vient
\startformula
\Align{
\NC X^n\NC =P(M)Q(M)+R(M)=0+aI_3+bM+cM^2\NR
\NC\NC ={n^2-3n+2\F 2}I_3+n(2-n)M+{n(n-1)\F 2}M^2\qquad(nâ©¾1)
}
\stopformula
\item La suite $\big(P_n(M)\big)_{nâ©¾1}$ n'est pas convergente. {\it Prouvons le par l'absurde en essayant d'Ã©viter de souffrir}.
En effet, si elle Ã©tait convergente alors 
\startformula
(I_3-M)Ã—P_n(M)={1\F n}(1-M)âˆ‘_{k=0}^{n-1}M^k={1\F n}\Q(I_3-M^n\W)
\stopformula
le serait aussi et en particulier, la suite ${1\F n}M^n$ serait convergente, ce qui n'est clairement pas le cas, vu l'expression trouvÃ©e Ã  la question prÃ©cÃ©dente.
\stopList
\item\startList
\item {\it Wow, des permutations maintenant et le symbÃ´le de Kronecker...qui n'est pas expliquÃ©, c'est mal...
\startformula
Î´_{i,j}=\System{
\NC 1 \NC \Si i=j\NR
\NC 0 \NC \Si iâ‰ j}
\stopformula
Autrement dit, la matrice $A_Ïƒ$ a un $1$ par ligne. Sur la ligne $i$, le $1$ est situÃ© sur la colonne de mÃªme rang que $Ïƒ(i)$, l'image par $i$ de la permutation
}
\item Notons $A_Ïƒ=(a_{i,j})_{1â©½iâ©½n\atop 1â©½jâ©½n}$, $A_Ï„=(b_{i,j})_{1â©½iâ©½n\atop 1â©½jâ©½n}$ et $A_ÏƒA_Ï„=(c_{i,j})_{1â©½iâ©½n\atop 1â©½jâ©½n}$. Soit $iâˆˆâŸ¦1,nâŸ§$ et $jâˆˆâŸ¦1,nâŸ§$. D'aprÃ¨s le cours, on a 
\startformula
\Align{
\NC c_{i,j}\NC \displaystyle=âˆ‘_{k=1}^na_{i,k}b_{k,j}=âˆ‘_{k=1}^n\underbrace{Î´_{i, Ïƒ(k)}Î´_{k,Ï„(j)}}_{\rlap{=0 \text{ si $iâ‰ Ïƒ(k)$ ou $kâ‰ Ï„(j)$ et $=1$ sinon}}}\NR
\NC\NC \displaystyle= Î´_{i, Ïƒ(Ïƒ^{-1}(i))}Î´_{Ïƒ^{-1}(i),Ï„(j)}=Î´_{Ïƒ^{-1}(i),Ï„(j)}=Î´_{i,Ïƒ(Ï„(j))}
}
\stopformula
(la seule valeur de $k$ pouvant donner autre chose que $0$ est $k=Ïƒ^{-1}(i)$ et on a Ã©galement $Ïƒ^{-1}(i)=Ï„(j) âŸºi=Ïƒ(Ï„(j))$ ). En particulier, on obtient que la matrice $A_ÏƒA_Ï„$ a les mÃªmes coefficients que la matrice $A_{Ïƒâˆ˜Ï„}$, de sorte que 
\startformula
A_ÏƒA_Ï„=A_Ïƒâˆ˜Ï„
\stopformula
{\it Pour info, les MP* font ce genre de question relativement souvent et ils en ont plusieurs comme cela Ã  tous leurs ds...
La, il valait mieux l'admettre peut Ãªtre ^^}
\item On a $A_{Id}=I_p$ (les $1$ sont tous sur la diagonale principale) et comme $A_ÏƒA_{Ïƒ^{-1}}=A_{Ïƒâˆ˜Ïƒ^{-1}}=A_{Id}=I_p$, nous remarquons que la matrice $A_Ïƒ$ est inversible, d'inverse 
$A_{Ïƒ^{-1}}$. 
\item Il y a $p!$ permutations de $âŸ¦1,pâŸ§$ et il y a donc autant de matrices de permutation
\item Comme il n'y a qu'un nombre fini de matrice de permutations et comme les matrices $(A_Ïƒ)^n=A_{Ïƒ^n}$ sont toutes des matrices de permutation pour $nâ©¾1$, il y en a au moins eux qui sont Ã©gales. autrement dit, 
il existe deux entiers distincts $p$ et $q$ tels que $(A_Ïƒ)^p=(A_Ïƒ)^q$. 
{\it Wow, on fait ce genre de raisonnement quand on fait de la thÃ©orie des groupes... Ã§a a l'air fun fun la prÃ©pa ECS Ã  st louis...}
\item Comme $(A_Ïƒ)^p=(A_Ïƒ)^q$ et comme ces matrice sont inversibles, on remarque que 
\startformula
(A_Ïƒ)^p\Q((A_Ïƒ)^q\W)^{-1}=I_r=(A_Ïƒ)^p(A_Ïƒ)^{-q}=(A_Ïƒ)^{p-q}
\stopformula
En particulier, il existe un entier $r=p-qâ‰ 0$ tel que $(A_Ïƒ)^r=I_p$
{\it en prenant pour $p$ le plus grand des deux entiers et pour $q$ le plus petit des entiers, on obtient Ã©galement que $r=q-p>0$ de sorte que $râ©¾1$}
\item La suite $(A_Ïƒ)^n$ est $r$-pÃ©riodique car 
\startformula
(A_Ïƒ)^{n+r}=(A_Ïƒ)^n(A_Ïƒ)^r=(A_Ïƒ)^nI-r=(A_Ïƒ)^n\qquad(nâ©¾1)
\stopformula
\item {\it Bon, la je crois que l'auteur souhaite nous voir faire un raisonnement avec les matrices identique Ã  celui utilisÃ© pour obtenir le lemme au 1 (que l'on a jamais utilisÃ©).
Si on fait le parallÃ¨le, la suite $(A_Ïƒ)^n$ est $r$-pÃ©riodique et donc $P_n(A_Ïƒ)$ est sensÃ© converger d'aprÃ¨s le lemme vers $y={1\F n}âˆ‘_{k=0}^{r-1}(A_Ïƒ)^k$, etc...\crlf
bref, passons Ã  l'exercice
}
\stopList
\stopList


\centerline{Correction de l'exercice}

{\it PrÃ©parons nous Ã  un festival de mÃ©thode MARRE}
\startList
\item Soit $kâˆˆâ„•$.  
\startitemize[1]
\item Montrons que $N_kâŠ‚N_{k+1}$. Soit $xâˆˆN_k=\ker(f^k)$. Alors $f^k(x)=0$ de sorte que $f^{k+1}(x)=f\Q(f^k(x)\W)=f(0)=0$ et par consÃ©quent $xâˆˆ\ker(f^{k+1})=N_{k+1}$. CQFD
\item Montrons que $I_{k+1}âŠ‚I_k$. Soit $yâˆˆI_{k+1}=\IM(f^{k+1})$. Alors il existe $xâˆˆâ„^n$ tel que $y=f^{k+1}(x)$ et alors, on remarque que $y=f^k(f(x))âˆˆ\IM(f^k)=I_k$. CQFD
\stopitemize 
\item Supposons qu'il n'existe pas d'entiers $pâ©½n$ tel que $N_p=N_{p+1}$. Alors la suite croissante de noyau $N_1âŠ‚N_2âŠ‚N_3âŠ‚â‹¯âŠ‚N_nâŠ‚N_{n+1}$ est strictement croissante (aucun noyau n'est Ã©gale au suivant), de sorte qu'en pmrenant leur dimension, on obtient que 
\startformula
\dim(N_1)<\dim(N_2)<\dim(N_3)<â‹¯<\dim(N_{n+1})
\stopformula
Mais alors, on obtient une suite strictement croissante de $n+1$ entiers de $âŸ¦0,nâŸ§$. De sorte que $\dim(N_1)=0$, d'oÃ¹ $f$ est injective et donc bijective mais dans ce cas tous les noyaux $N_k$ valent $\{0\}$ et on a notre contradiction...
CQFD, il existe au moins un entier $pâ©½n$ tel que $N_p=N_{p+1}$.
{\it Il y a une idÃ©e importante Ã  retenir ici : quand une application $f$ a un noyau de dimension non nulle, les noyaux itÃ©rÃ©s de $f$ ont une dimension qui augmente strictement puis qui devient constante}
\item $I_{p+1}=I_p$ d'aprÃ¨s a) Et il rÃ©sulte du thÃ©orÃ¨me du rang que 
\startformula
\dim(I_{p+1})=\dim(â„^n)-\dim(N_{p+1})=\dim(â„^n)-\dim(N_p)=\dim(I_p)
\stopformula
Comme les noyaux ont mÃªme dimension finie et l'un est inclus dans l'autre, on a $I_{p+1}=I_p$. 
\item Pour $kâˆˆâ„•$, prouvons par rÃ©currence la proposition $\mc P_k:N_{p+k}=N_p$. 
\startitemize[1]
\item Les propositions $\mc P_0$ et $\mc P_1$ sont vraies d'aprÃ¨s le rÃ©sultat de la question b 
\item Supposons la proposition $\mc P_k$ pour un entier $kâ©¾0$. 

Rappelons que $N_kâŠ‚N_{p+k+1}$ (suite croissante de noyaux) et montrons maintenant que $N_{p+k+1}âŠ‚N_p$.

Soit $xâˆˆN_{p+k+1}=\ker(f^{p+k+1})$. alors, on a $0=f^{p+k+1}(x)=f^{p+k}\big(f(x)\big)$. A fortiori, $f(x)âˆˆ\ker(f^{p+k})=N_{p+k}=N_p=\ker(f^p)$ de sorte que 
\startformula
0=f^p\big(f(x)\big)=f^{p+1}(x).
\stopformula
En particulier $xâˆˆ\ker(f^{p+1})=N_{p+1}=N_p$. CQFD

En conclusion, $N_{p+k+1}âŠ‚N_p$ et $N_p=N_{p+k+1}$ de sorte que la proposition $\mc P_{k+1}$ est vraie
\stopitemize
En conclusion, la proposition $\mc P_k$ est vraie pour $kâˆˆâ„•$. 
\item On remarque que $N_pâˆ©I_p=\{0\}$. En effet, si $yâˆˆN_pâˆ©I_p$, alors $f^p(y)=0$ et il existe un $xâˆˆâ„^n$ tel que $y=f^p(x)$ mais alors $0=f^p(y)=f^p(f^p(x))=f^{2p}(x)$
et donc $xâˆˆN_{2p}=N_p$ de sorte que $y=f^p(x)=0$. .
En particulier, nous obtenons que $I_pâŠ•N_p$. Par ailleurs, il rÃ©sulte du thÃ¨orÃ¨me du rang appliquÃ© Ã  la fonction $f^p$ que 
$\dim(â„^n)=\dim\ker (f^p)+\dim(\IM(f^p)=\dim N_p+\dim I_p=\dim(N_pâŠ•I_p)$.
Comme $I_pâŠ•N_pâŠ‚â„^n$, il vient
\startformula
â„^n=I_pâŠ•N_p
\stopformula
{\it magnifique...}

\stopList







\stoptext
\stopcomponent
\endinput
