\startcomponent component_DS1
\project project_Res_Mathematica
\environment environment_Maths
\environment environment_Inferno
\xmlprocessfile{exo}{xml/Limbo_Exercices.xml}{}
\iffalse
\setupitemgroup[List][1][R,inmargin][after=,before=,left={\bf Exo },symstyle=bold,inbetween={\blank[big]}]
\setupitemgroup[List][2][n,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][3][a,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][4][1,joineup,nowhite]
\fi

%\setupitemgroup[List][1][A,inmargin][after=,before=,left={\bf Exo },symstyle=bold,inbetween={\blank[big]}]
%\setupitemgroup[List][1][R,joineup][after=,before=,inbetween={\blank[small]}]
%\setupitemgroup[List][1][n,inmargin][after=,before=,left={\bf Exo },symstyle=bold,inbetween={\%blank[big]}]
%\setupitemgroup[List][2][n,joineup][after=,before=,inbetween={\blank[small]}]
%\setupitemgroup[List][3][a,joineup][after=,before=,inbetween={\blank[small]}]
%\setupitemgroup[List][4][1,joineup,nowhite]
%\setupitemgroup[List][4][a,joineup,nowhite]
\definecolor[myGreen][r=0.55, g=0.76, b=0.29]%
\setuppapersize[A4]
\setuppagenumbering[location=]
\setuplayout[header=0pt,footer=0pt]
\def\conseil#1{{\myGreen\it #1}}%


\starttext
\setupheads[alternative=middle]
%\showlayout
\def\gah#1{\margintext{Exercice #1}}

\iftrue
\page
\centerline{\bfb DEVOIR MAISON 14}
\blank[big]

\setupitemgroup[List][1][A,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][2][n,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][3][a,joineup][after=,before=,inbetween={\blank[small]}]
\setupitemgroup[List][4][1,joineup,nowhite]


\centerline{\bf CORRECTION DU PROBL√àME 1}
\blank[big]
\startList%
\item%1 G√©n√©ralit√©s
\startList
\item%a

\startitemize[1]
\item $\mc C_A$ est inclus, par d√©finition, dans $\mc M_n(‚Ñù)$, qui est un $‚Ñù$-espace vectoriel de r√©f√©rence 
\item $\mc C_A$ contient la matrice nulle car $A√ó0=0=0√óA$ de sorte que $\mc C_A‚â†\emptyset$
\item Soient $(Œª,Œº)‚àà‚Ñù^2$ et $(M,N)‚àà\mc C_A^2$. Comme $AM=MA$ et $AN=NA$, il r√©sulte de la distributivit√© du produit matriciel et de la loi du scalaire mobile que  
\startformula
(ŒªM+ŒºN)√óA=ŒªMA+ŒºNA=ŒªAM+ŒºAN=(ŒªM+ŒºN)√óA
\stopformula
En particulier, $ŒªM+ŒºN‚àà\mc C_A$. L'ensemble $\mc C_A$ est donc stable par combinaison lin√©aire.
\stopitemize
En conclusion, $\mc C_A$ est un sous-espace vectoriel de $\mc M_n(‚Ñù)$. 
\item%b
Pour $M‚àà\mc M_n(‚Ñù)$, et $Œª‚àà‚Ñù$, il r√©sulte de l'associativit√© du produit, de la loi du scalaire mobile et du fait que $I_n$ soit un √©l√©ment neutrte pour la multiplication, que 
\startformula
M√ó(ŒªI_n)=Œª(M√óI_n)=ŒªM=Œª(I_n√óM)=(ŒªI_n)√óM
\stopformula
En particulier $M‚àà\mc C_{ŒªI_n}$, de sorte que 
\startformula
\mc C_{ŒªI_n}=\mc M_n(‚Ñù)\qquad(Œª‚àà‚Ñù).
\stopformula
\item Soit $A‚àà\mc M_n(‚Ñù)$. Si $A‚àà\Vect(I_n)$, il r√©sulte des calculs effectu√©s dans la question pr√©c√©dente que 
$\dim(\mc C_A)=\dim\big(\mc M_n(‚Ñù)\big)=n^2‚©æ2$.

Si $A\‚àâ\Vect(I_n)$, alors $\mc C_A$ est un sous-espace vectoriel de $\mc M_n(‚Ñù)$, contenant les matrices $I_n$ (car $A√óI_n=A=I_n√óA$) et $A$ (car $A√óA=A^2=A√óA$). 
Comme la famille $\{I_n,A\}$ est libre (puisque $A‚àâ\Vect(I_n)$), $\mc C_A$ est de dimension au moins $2$ car il contient une famille libre de deux vecteurs.
\crlf
Dans tous les cas, $\mc C_A$ est au moins de dimension $2$.
\item {\it Houla, c'est une question technique √ßa... qui exploite le fait que les bases permettent de transformer (via isomorphisme) vecteurs en coordonn√©es, applications lin√©aires en matrices, etc...}
Soit $\Fun{œà:\mc L(‚Ñù^n)‚ÜíM_n(‚Ñù)|f‚Ü¶\mc Mat_‚Ñ¨(f)}$ l'isomorphisme (d'apr√®s le cours) associant √† un endomorphisme $f$ de $‚Ñù^n$, sa matrice dans la base $‚Ñ¨$.
Alors, je pr√©tends que $œà$ transforme $\mc C_f$ en $\mc C_A$, c'est √† dire que $œà(\mc C_f)=\mc C_A$, ce qui implique (les deux espaces √©tant isomorphes) que 
\startformula
\dim(\mc C_f)=\dim(\mc C_A)
\stopformula
En effet, comme $A= \mc Mat_‚Ñ¨(f)=œà(f)$, pour $f‚àà‚Ñí(‚Ñù^n)$, nous remarquons que 
\startformula
\Align{
\NC g‚àà\mc C_f\NC ‚ü∫ f‚àòg=g‚àòf‚ü∫\mc Mat_‚Ñ¨(f‚àòg)=\mc Mat_‚Ñ¨(g‚àòf)\NR
\NC \NC ‚ü∫\mc Mat_‚Ñ¨(f)√ó\mc Mat_‚Ñ¨(g)=\mc Mat_‚Ñ¨(g)√ó\mc Mat_‚Ñ¨(f)\NR
\NC \NC ‚ü∫\mc A√ó\mc Mat_‚Ñ¨(g)=\mc Mat_‚Ñ¨(g)√óA\NR
\NC\NC ‚ü∫\mc Mat_‚Ñ¨(g)‚àà\mc C_A\NR
\NC\NC ‚ü∫ œà(g)‚àà\mc C_A
}
\stopformula
A fortiori, on a bien $œà(\mc C_f)=œà(\mc C_A)$.
\item {\it du Scilab !}\crlf
\starttyping
function [r]=commutables(A,B)
   r = A*B == B*A
endfunction
\stoptyping
\stopList
\item%2
\startList
\item%a
{\it On peut utiliser la m√©thode MARRE mais on va faire ici plus court/√©l√©gant via des √©quivalences}\crlf
Pour $M‚àà\mc M_n(‚Ñù)$, nous remarquons que 
\startformula
\Align{
\NC M‚àà\mc C_B\NC ‚ü∫M√óB=B√óM‚ü∫M\Q(A-{\text{tr}(A)\F 2}I_2\W)=\Q(A-{\text{tr}(A)\F 2}I_2\W)M\NR
\NC\NC MA-{\text{tr}(A)\F 2}M=AM-{\text{tr}(A)\F 2}‚ü∫MA=AM\NR
\NC\NC ‚ü∫M‚àà\mc C_A
}
\stopformula
En particulier, nous avons $\mc C_B=\mc C_A$. 
\item Nous remarquon que 
\startformula
B=\Matrix{
\NC {a-d\F 2}\NC b\NR
\NC c\NC {d-a\F 2}}\qquad B^2=\Matrix{
\NC \Q({a-d\F 2}\W)^2+bc\NC {a-d\F 2}b+b{d-a\F 2}\NR
\NC c{a-d\F 2}+{d-a\F 2}c\NC bc+\Q({d-a\F 2}\W)^2
}=\Q(bc+\Q({d-a\F 2}\W)^2\W)I_2
\stopformula
En particulier, pour $r=bc+\Q({d-a\F 2}\W)^2$ et $P=x^2-rI_2$, nous avons 
\startformula
P(B)=B^2-rI_2=0
\stopformula
De sorte que $P$ est un polyn√¥me annulateur de $B$.
\item Soient $r‚àà‚Ñù$ et $N=\Matrix{\NC a\NC b\NR \NC c\NC d}‚àà\mc M_2(‚Ñù)$. alors, on a 
\startformula
\Align{[align={right, left,left}]
\NC N‚àà\mc C_M\NC ‚ü∫\NC NM=MN‚ü∫\Matrix{\NC a\NC b\NR\NC c\NC d}√ó\Matrix{\NC 0\NC r\NR\NC 1\NC 0}=\Matrix{\NC 0\NC r\NR\NC 1\NC 0}√ó\Matrix{\NC a\NC b\NR\NC c\NC d}\NR
\NC \NC ‚ü∫\NC \Matrix{
\NC b\NC ar\NR\NC d\NC cr}=\Matrix{
\NC rc\NC rd\NR \NC a\NC b}\NR
\NC \NC ¬†‚ü∫\NC \System{
\NC b=rc\NR
\NC ar=rd\NR
\NC d=a\NR
\NC cr=b
}\NR
\NC\NC ‚ü∫\NC \System{
\NC b=rc\NR
\NC d=a
}
}
\stopformula
A fortiori, on a
\startformula
\mc C_M=\Q\{aI_2+c\Matrix{\NC 0\NC r\NR\NC 1\NC 0}:(a,c)‚àà‚Ñù^2\W\}=\Vect\Q(I_2, \Matrix{\NC 0\NC r\NR\NC 1\NC 0}\W)
\stopformula
De sorte que $\mc C_M$ est de dimension $2$ quel que soit $r‚àà‚Ñù$
\item {\it Question bizarrement pos√©e. Il faut lire la question suivante pour voir o√π ils veulent en venir... }\crlf
Supposons que les trois familles de deux vecteurs $(e_1,f(e_1)$, $(e_2, f(e_2))$ et $(e_1+e_2, f(e_1+e_2))$ soient li√©es. 
Comme $e_1$, $e_2$ et $e_1+e_2$ sont des vecteurs non nuls, il existe $(a,b,c)‚àà‚Ñù^3\ssm\{(0,0,0)\}$ tels que 
\startformula
\System{
\NC f(e_1)=ae_1\NR
\NC f(e_2) = be_2\NR
\NC f(e_1+e_2)=c(e_1+e_2)
}
‚üπ 0=f(e_1+e_2)-f(e_1)-f(e_2)=(c-a)e_1+(c-b)e_2=0
\stopformula
Comme $(e_1,e_2$ est libre (puisque c'est une base), nous avons forc√©ment $c-a=0=c-b$, de sorte que $a=c=b$.
Nous en d√©duisons alors que $f(e_1)=ae_1=a\text{Id}(e_1)$ et $f(e_2)=be_2=ae_2=a\text{Id}(e_2)$.
Comme les applications lin√©aires $f$ et $a\text{Id}$ coincident sur la base $(e_1,e_2)$, elles sont √©gales, de sorte que 
\startformula
f=a\text{Id}
\stopformula
Ceci contredit la d√©finition de $f$, car la matrice canoniquement associ√©e √† $f$ est $B=A-{\text{tr}(A)\F 2}I_2‚â†aI_2$, en effet $(A, I_2)$ est libre
\item Il r√©sulte du raisonnement par l'absurde  men√© √† la question pr√©c√©dente qu'il existe un vecteur $v‚àà‚Ñù^2$ tel que $(v, f(v))$ soit libre car les trois familles 
$(e_1, f(e_1)$, $(e_2, f(e_2))$ et $(e_1+e_2, f(e_1+e_2))$ ne peuvent pas √™tre toutes li√©es. 
A fortiori, la famille libre $ùìì=(v, f(v))$ de deux vecteurs de $‚Ñù^2$, en constitue une base. \crlf
{\it Accrochez vous !}\crlf
Comme $X^2-r$ est un polyn√¥me annulateur de $B$, c'est √©galement un polyn√¥me annulateur de $f$, de sorte que
$f^2-r\text{Id}=0$. 

En particulier, $f^2(v)=r\text{Id}(v)=rv$. De sorte que 
\startformula
\mc Mat_ùìì(f)=\Matrix{\NC 0\NC r\NR
\NC 1\NC 0}=M
\stopformula
\item {\it Faisons la synth√®se des questions pr√©c√©dentes}
Il r√©sulte de la question 2a que $\dim(\mc C_A)=\dim(\mc B)$. Or d'apr√®s la question 1d, il vient 
$\dim(\mc C_B)=\dim(\mc C_f)$. Or dans la base $ùìì$, $\mc Mat_ùìì(f)=M$, de sorte que l'on peut montrer que 
$\dim(\mc C_f)=\dim(\mc C_M)$ {\it (un peu comme √† la question 1d, sauf qu'au lieu d'utiliser la base canonique, on utilise la base $ùìì$)}
Et enfin, il r√©sulte de la question 2c que $\dim(\mc C_M)=2$ de sorte que $\dim(\mc C_A)=2$. Comme $(A, I_2)$ est une famille libre de $\mc C_A$, c'en est une base.
{\it Une mani√®re bien tortur√©e d'arrivr √† ce r√©sultat, dans un cas relativement simple...la dimension $2$}
\stopList
\item%3
\startList
\item%a
{\it On remarque au brouillon que $C_1-C_2=0$ et que $C_1-C_3=0$...}
Les vecteurs $(1,-1,0)$ et $(1,0,-1)$ appartiennent au noyau de $f$ car
\startformula
A√ó\Matrix{
\NC 1\NR
\NC -1\NR
\NC 0} = \Matrix{
\NC 1-1+0\NR
\NC -1+1+0\NR
\NC 1-1+0
}=0\Et A√ó\Matrix{
\NC 1\NR
\NC 0\NR
\NC -1} = \Matrix{
\NC 1+0-1\NR
\NC -1+0+1\NR
\NC 1+0-1
}=0
\stopformula
Comme $A$ est clairement de rang $1$, il r√©sulte du th√®or√®me du rang que $\dim(\ker f)=\dim(‚Ñù^3)-\rg(f)=3-1-2$ de sorte que 
\startformula
\ker(f)=\Vect\big((1,-1,0),(1,0,-1)\big)
\stopformula
Ensuite, l'image de $f$ qui est de dimension $1$, est $\IM(f)=\Vect(f(1,0,0))=\Vect\big((1,-1,1)\big)$.
{\it le sujet demande l'image et le noyau de $a$, un l√©ger abus, il derait demander le noyau et l'image de l'endomorphisme $f$ associ√© √† $A$ dans la base canonique}
\item On remarque que $A^2=\Matrix{
\NC 1-1+1\NC 1-1+1\NC 1-1+1\NR
\NC -1+1-1\NC -1+1-1\NC -1+1-1\NR
\NC 1-1+1\NC 1-1+1\NC 1-1+1}=A$. 

A fortiori, $A$ est la matrice d'un projecteur, donc $f$ est un projecteur.
L'endomorphisme $f$ est donc une projection sur son image $\IM (f)$ d√©termin√©e pr√©c√©demment, parall√©lement √† son noyau, d√©termin√©e pr√©c√©demment √©galement.
\item $P$ est inversible car c'est une matrice de $\mc M_3(‚Ñù)$ de rang $3$. En effet
\startformula
\rg(P)=\rg\Matrix{
\NC 2\NC 1\NC 0\NR
\NC -1\NC -1\NC 0\NR
\NC 1\NC 0\NC -1}=\rg\Matrix{
\NC 2\NC 1\NC 0\NR
\NC -1\NC -1\NC 0\NR
\NC 0\NC 0\NC -1}=\rg\Matrix{
\NC 1\NC 0\NC 0\NR
\NC -1\NC -1\NC 0\NR
\NC 0\NC 0\NC -1}=3
\stopformula
{\it J'aurais mieux fait d'inverser directement $P$, vu qu'on a aussi besoin de l'inverse...}
En d√©duisons que la matrice $P$ est inversible, d'inverse 
\startformula
P^{-1}=Q=\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
},
\stopformula
du calcul
\startformula
Q√óP=
\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
}√ó\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -1\NC 0\NR
\NC 1\NC 0\NC -1
}=\Matrix{
\NC 1-1+1\NC 1-1\NC 1-1\NR
\NC -1+2-1\NC -1+2\NC -1+1\NR
\NC 1-1\NC 1-1\NC 1
}=I_3.
\stopformula
 {\it J'ai fait la recherche de matrice inverse au brouillon bien s√ªr, avec l'algorithme standard}

 \item $Œ¶$ est un automorphisme de $\mc M_n(‚Ñù)$ car c'est un endomorphisme de $\mc M_n(‚Ñù)$
 \startitemize[1]
\item  $\mc M_n(‚Ñù)$ est un $‚Ñù$-espace vectoriel (au d√©part et √† l'arriv√©e)
\item Pour $M‚àà \mc M_n(‚Ñù)$, $P√óM√óP^{-1}$ est d√©finit et appartient √† $\mc M_n(‚Ñù)$ en tant que produit de matrices r√©elles carr√©es de taille $n$.
De sorte que $Œ¶:\mc M_n(‚Ñù)‚Üí\mc M_n(‚Ñù)$ est une application
\item Soient $(Œª,Œº)‚àà‚Ñù¬≤$ et $(M,N)‚àà\mc M_n(‚Ñù)^2$, il r√©sulte de la distributivit√© et de la loi du scalaire mobile que  
\startformula
\Align{
\NC Œ¶(ŒªM+ŒºN)\NC =P(ŒªM+ŒºN)P^{-1}=P(ŒªM)P^{-1}+P(ŒºN)P^{-1}\NR
\NC\NC =ŒªPMP^{-1}+ŒºPNP^{-1}\NR
\NC\NC=ŒªŒ¶(M)=+ŒºŒ¶(N)
}
\stopformula
\stopitemize
De plus, le noyau de $Œ¶$ est r√©duit √† la matrice nulle car (en multipliant par $P$ √† droite et $P^{-1}$ √† gauche)
\startformula
M‚àà\ker(Œ¶)‚ü∫Œ¶(M)=0‚ü∫PMP^{-1}=0‚ü∫PM=0√óP=0‚ü∫M=P^{-1}√ó0=0
\stopformula
A fortiori, $Œ¶$ est injective et m√™me (espace vectoriel de m√™me dimension finie au d√©part et √† l'arriv√©e) bijective
C'est doncun automorphisme de $\mc M_n(‚Ñù)$. 
Enfin, pour une matrice $M$ de $\mc M_n(‚Ñù)$, nous remarquons que $Œ¶^{-1}(M)=P^{-1}MP$ et aussi que (multiplication par $P^{-1}$ √† gauche et par $P$ √† droite)
\startformula
\Align{
\NC M‚àà\mc C_{PAP^{-1}}\NC ‚ü∫M√óPAP^{-1}=PAP^{-1}√óM\NR
\NC\NC ‚ü∫P^{-1}M√óPAP^{-1}=AP^{-1}√óM\NR
\NC\NC ‚ü∫P^{-1}M√óPA=AP^{-1}√óM√óP\NR
\NC\NC ‚ü∫P^{-1}MP√óA=A√óP^{-1}MP\NR
\NC\NC ‚ü∫Œ¶^{-1}(M)√óA=A√óŒ¶^{-1}(M)\NR
\NC\NC ‚ü∫ Œ¶^{-1}(M)‚àà\mc C_A\NR
\NC\NC ‚ü∫ M‚ààŒ¶(\mc C_A)\NR
}
\stopformula
A fortiori, nous obtenons que $Œ¶(\mc C_A)=C_{PAP^{-1}}=C_{Œ¶(A}$
\item Nous remarquons que 
\startformula
\Align{
\NC PAP^{-1}\NC =PAQ=\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
}√ó\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -1\NC -1\NR
\NC 1\NC 1\NC 1
}√ó\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
}\NR
\NC\NC =\Matrix{
\NC 1\NC 1\NC 1\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0
}√ó\Matrix{
\NC 1\NC 1\NC 1\NR
\NC -1\NC -2\NC -1\NR
\NC 1\NC 1\NC 0
}=\Matrix{
\NC 1\NC 0\NC 0\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0
}=D¬†}
\stopformula

{\it Pour info, nous venons de diagonaliser la matrice $A$ (algorithme ECS2), c'est sens√© simplifier le probleme car $D$ est plus simple que $A$}
Etant donn√©e une matrice $M=\Matrix{
\NC a\NC b\NC c\NR
\NC d\NC e\NC f\NR
\NC g\NC g\NC i
}$, nous avons
\startformula
\Align{
\NC M‚àà\mc C_D\NC ‚ü∫MD=DM‚ü∫\Matrix{
\NC a \NC 0\NC 0\NR
\NC d\NC 0\NC 0\NR
\NC g\NC 0\NC 0}=\Matrix{
\NC a\NC b\NC c\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0\NR
}\NR
\NC \NC ‚ü∫ M = \Matrix{
\NC a\NC 0\NC 0\NR
\NC 0\NC e\NC f\NR
\NC 0\NC g\NC i
}
}
\stopformula
De sorte que $\mc C_D=\mc C_{PAP^{-1}}=\Vect\Q(D, \Matrix{
\NC 0\NC 0\NC 0\NR
\NC 0\NC 1\NC 0\NR
\NC 0\NC 0\NC 0
},  \Matrix{
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 1\NR
\NC 0\NC 0\NC 0
},  \Matrix{
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 1\NC 0
},  \Matrix{
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 0\NR
\NC 0\NC 0\NC 1
}\W)$
et que $\dim(\mc C_A)=\dim(Œ¶(\mc C_A))\dim(\mc C_D)=5$
{\it Wahh, c'est bourrin quand m√™me...}
\stopList
\item \startList
\item Comme $p$ est un projecteur de $‚Ñù^n$, on sait que
\startformula
‚Ñù^n=\ker p ‚äï \IM p
\stopformula
Comme $p$ est de rang $p$, la dimension de son image est $p$.
Soit $e_1,‚Ä¶,e_p$ une base de son image et $e_{p+1}, ‚Ä¶,e_n$ une base de son noyau (qui est de dimension $n-p$, d'apr√®s l'identit√© ci-dessus).
Alors, d'apr√®s la propri√©t√© de concat√©nation des bases, $‚Ñ¨=(e_1, ‚Ä¶, e_n)$ est une base de $‚Ñù^n$ et comme les vecteurs de l'image de $p$ sont  invariants par $p$ 
alors que les vecteurs du noyau de $p$ sont transform√©s en $0$, on a 
\startformula
\mc Mat_{‚Ñ¨}(p)=\Matrix{
\NC 1\NC 0\NC ‚ãØ\NC ‚ãØ\NC ‚ãØ\NC 0\NR
\NC 0\NC ‚ã±\NC‚ã± \NC\NC \NC‚ãÆ\NR
\NC‚ãÆ\NC ‚ã± \NC 1\NC ‚ã±\NC \NC‚ãÆ\NR
\NC‚ãÆ\NC  \NC ‚ã±\NC 0\NC ‚ã± \NC‚ãÆ\NR
\NC‚ãÆ\NC  \NC \NC ‚ã±\NC ‚ã± \NC‚ãÆ\NR
\NC 0\NC ‚ãØ \NC ‚ãØ\NC ‚ãØ\NC ‚ãØ \NC 0
}=\Matrix{\NC I_r\NC 0\NR\NC 0\NC 0}=J_r,
\stopformula
La matrice ci dessus contenant $r$ $1$ sur la diagonale principale
\item $f$ appartient √† $\mc C_p$ si et seulement si $f$ commute avec $p$. Proc√©dons {\it avec la m√©thode MARRE} par double implication.
Supposons que $p$ commute avec $f$. Alors, pour $x‚àà\ker(p)$, on a
\startformula
p\big(f(x)\big)=p‚àòf(x)=f‚àòp(x)=f\big(p(x)\big)=f(0)=0
\stopformula
De sorte que $p(x)‚àà\ker(p)$. Le noyau de $p$ est donc stable par $f$.
Par ailleurs, si $y‚àà\IM(p)$, alors il existe $x‚àà‚Ñù^n$ tel que $y=p(x)$ et alors
\startformula
f(y)=f\big(p(x)\big)=f‚àòp(x)=p‚àòf(x)=p\big(f(x)\big)‚àà\IM(p)
\stopformula
De sorte que l'image de $p$ est √©galement stable par $f$. \crlf
R√©ciproquement, supposons que le noyau et l'image de $p$ soit stable par $f$.
Soit $x‚àà‚Ñù^n$. Comme $‚Ñù^n=\ker p ‚äï \IM p$, il existe un vecteur $y‚àà\IM(p)$ (et donc $y=p(y)$) et un vecteur $z‚àà\ker(p)$ (et donc $p(z)=0$) tels que $x=y+z$.
A fortiori, commeles vecteurs de l'image de $p$ sont invariants par $p$, il vient 
\startformula
\Align{
\NC f‚àòp(x)\NC =f\big(p(x)\big)=f\big(p(y+z)\big)=f\big(p(y)+p(z)\big)=f\big(y+0\big)\NR
\NC \NC =\underbrace{f(y)}_{‚àà\IM(p)}=p\big(f(y)\big) + 0=p\big(f(y)\big)+p\big(\underbrace{f(z)}_{‚àà\ker(p)}\big)\NR
\NC\NC =p\big(f(y+z)\big)=p\big(f(x)\big)\NR
\NC\NC=p‚àòf(x)
}
\stopformula
En particulier, les applications $f‚àòp$ et $p‚àòf$ coincident sur $‚Ñù^n$, donc elles sont √©gales. De sorte que $p‚àòf=f‚àòp$, c'est √† dire qu'elles commutent.
{\it Ouch, dur...}
\item La matrice de $f‚àà\mc C_p$ dans la base de la question a doit avoir la forme $\Matrix{\NC M_r\NC 0\NR\NC 0\NC N_{n-r}}$, 
avec $M_r$ matrice carr√©e quelconque de taille $r$ et $N_{n-r}$ matrice carr√©e quelconque de taille $n-r$, 
Car le noyau et l'images de $p$ doivent √™tre stables par $f$, 
{\it $M_r$ est la matrice de la restriction de $f$ √† $\IM(p)$ et $N_{n-r}$ est la matrice de la restriction de $f$ √† $\ker(p)$}
\item En particulier, comme $\mc C_p$ est l'ensemble des applications $f$ dont la matrice (dans la base de a) v√©rifie les contraintes √©nonc√©es dans la question pr√©c√©dentes, on a 
\startformula
\dim(\mc C_p) = r^2+(n-r)^2
\stopformula
\item $M$ est la matrice d'un projecteur $p$ de rang $r=\rg(M)$. A fortiori, on a 
\startformula
\dim(\mc C_M)= \dim(\mc C_p) = r^2+(n-r)^2=\rg(M)^2+\big(n-\rg(M)\big)^2
\stopformula
\stopList


\centerline{\bf Correction du Probl√®me 2}

{\bf 0.} Comme $\displaystyle\lim_{n‚Üí+‚àû}\arctan(n)=+{œÄ\F 2}$, comme $\displaystyle\lim_{n‚Üí‚àû}{\sin n\F n}=0$ et comme 
\startformula
n\sin{1\F n}‚àºn√ó{1\F n}=1‚Üí1,
\stopformula
il vient
\startformula
\lim_{n‚Üí+‚àû}M_n=\Matrix{\NC {œÄ\F 2}\NC 0\NR\NC 1\NC 3}
\stopformula
\startList
\item Soit $n‚àà‚Ñï$. Slors, nous d√©duisons du changement d'indice $i'=i-r$ et de la $r$-p√©riodicit√© de la suite $x$ que
\startformula
\Align{
\NC \displaystyle{1\F r}‚àë_{i=n}^{n+r-1}x_i-y\NC\displaystyle={1\F r}‚àë_{i=n}^{n+r-1}x_i-{1\F r}‚àë_{i=0}^{r-1}x_i\NR
\NC \NC \displaystyle= {1\F r}\Q(‚àë_{i=r}^{n+r-1}x_i-‚àë_{i=0}^{n-1}x_i\W)\NR
\NC\NC \displaystyle= {1\F r}\Q(‚àë_{i'=0}^{n-1}x_{i'+r}-‚àë_{i=0}^{n-1}x_i\W)\NR
\NC\NC \displaystyle= {1\F r}\Q(‚àë_{i'=0}^{n-1}x_{i'}-‚àë_{i=0}^{n-1}x_i\W)=0\NR
}
\stopformula
En particulier, nous obtenons que $\displaystyle y={1\F r}‚àë_{i=n}^{n+r-1}x_i$ pour $n‚àà‚Ñï$.
\item Pour $n‚©æ1$, nous remarquons que 
\startformula
\Align{
\NC w_{n+r}\NC =\displaystyle (n+r)y_{n+r}-(n+r)y=(n+r){1\F n+r}‚àë_{i=0}^{n+r-1}x_i-(n+r)y\NR
\NC \NC \displaystyle= ‚àë_{i=0}^{n+r-1}x_i-(n+r)y\NR
\NC \NC \displaystyle= ‚àë_{i=0}^{n-1}x_i + ‚àë_{i=n}^{n+r-1}x_i-(n+r)y\NR
\NC \NC \displaystyle= ny_n + \underbrace{‚àë_{i=n}^{n+r-1}x_i}_{ry}-(n+r)y\NR
\NC \NC = ny_n -ny=w_n
}
\stopformula
En particulier, la suite $(w_n)_{n‚©æ1}$ est $r$-p√©riodique.
\item Une suite $r$-p√©riodique $(x_n)_{n‚©æ0}$ est born√©e car 
\startformula
|x_k|‚©ΩM=\max\big\{|x_0|, ‚ãØ, |x_{r-1}|\big\}\qquad(k‚©æ0)
\stopformula
En effet, pour $k‚àà‚Ñï$, il r√©sulte de la division euclidienne de $k$ par $r$ qu'il existe deux entiers $q‚©æ0$ et $s‚àà‚ü¶0,r-1‚üß$ tel que $k=qr+s$ et alors, on a 
\startformula
|x_k|=|x_{qr+s}|=|w_s|‚©ΩM
\stopformula
\item Comme la suite $w$ est $r$-p√©riodique, elle est born√©e, de sorte qu'il existe un nombre r√©el $M$ v√©rifiant $|w_n|‚©ΩM$ pour $n‚©æ1$.
Alors, nous obtenons que 
\startformula
|y_n-y|=\Q|{w_n\F n}\W|={|w_n|\F n}‚©Ω{M\F n}\qquad (n‚©æ1).
\stopformula
Comme $\displaystyle\lim_{n‚Üí+‚àû}{M\F n}=0$, il r√©sulte de la propri√©t√© des gendarmes que 
\startformula
\displaystyle\lim_{n‚Üí+‚àû}(y_n-y)=0
\stopformula
et donc que $\displaystyle\lim_{n‚Üí+‚àû}y_n=y$.
\stopList
\item \startList
\item Nous remarquons que 
\startformula
\System{
\NC B-{1\F 6}C=A\NR
\NC B+C=I_2}‚ü∫\System{
\NC B-{1\F 6}C=A\NR
\NC {7\F 6}C=I_2-A}‚ü∫
\System{
\NC B=A+{1\F 7}(I_2-A)={1\F 7}(I_2+6A)={1\F 7}\Matrix{\NC 3\NC 4\NR \NC 3\NC 4}\NR
\NC C={6\F 7}(I_2-A)={6\F 7}\Matrix{\NC {2\F 3}\NC {-2\F 3}\NR \NC{-1/2}\NC {1\F 2}}
={1\F 7}\Matrix{\NC 4\NC -4\NR \NC -3\NC 3}
}
\stopformula
\item De simples calculs matriciels donnent
\startformula
\Align{
\NC B^2\NC ={1\F 7^2}\Matrix{\NC 21\NC 28\NR \NC 21\NC 28}={1\F 7}\Matrix{\NC 3\NC 4\NR \NC 3\NC 4}=B\NR
\NC C^2\NC ={1\F 7^2}\Matrix{\NC 28\NC -28\NR \NC -21\NC 21}={1\F 7}\Matrix{\NC 4\NC -4\NR \NC -3\NC 3}=C\NR
\NC BC\NC ={1\F 7^2}\Matrix{\NC 12-12\NC -12+12\NR \NC 12-12\NC -12+12}=0\NR
\NC CB\NC ={1\F 7^2}\Matrix{\NC 12-12\NC 16-16\NR \NC -9+9\NC -12+12}=0\NR
}
\stopformula
En particulier, $B$ et $C$ sont des matrices de projecteurs qui commutent.
\item Pour $n‚©æ1$, il r√©sulte alors du bin√¥me de Newton ($B$ et $C$ commutent) que
\startformula
\Align{
\NC A^n\NC \displaystyle=\Q(B-{1\F 6}C\W)^n=‚àë_{k=0}^n{n\choose k}\Q(-{1\F 6}C\W)^kB^{n-k}\NR
\NC\NC \displaystyle=B^n+\Q(-{1\F 6}C\W)^n+‚àë_{k=1}^{n-1}{n\choose k}\Q(-{1\F 6}C\W)^kB^{n-k}\NR
\NC\NC \displaystyle=B+\Q(-{1\F 6}\W)^nC+‚àë_{k=1}^{n-1}{n\choose k}\Q(-{1\F 6}\W)^k\underbrace{CB}_{0}\NR
\NC\NC \displaystyle=B+\Q(-{1\F 6}\W)^nC
}
\stopformula
En particulier, nous obtenons que $A^n=B+\Q(-{1\F 6}\W)^nC‚àà\Vect(B,C)$
\item Il r√©sulte du calcul pr√©c√©dent que $\lim_{n‚Üí+‚àû}A^n=B$. Par ailleurs, nous d√©duisons de la formule des sommes g√©om√©triques que 
\startformula
\Align{
\NC P_n(A)\NC \displaystyle={1\F n}‚àë_{k=0}^{n-1}A^k={1\F n}\Q(I_2+‚àë_{k=1}^{n-1}\Q(B+\Q(-{1\F 6}\W)^kC\W)\W)\NR
\NC\NC \displaystyle={1\F n}\Q(I_2+(n-1)B+ \Q(‚àë_{k=1}^{n-1}\Q(-{1\F 6}\W)^k\W)C\W)\NR
\NC\NC \displaystyle={1\F n}\Q(I_2+(n-1)B+ {-{1\F 6}-\Q(-{1\F 6}\W)^n\F 1+{1\F 6}}C\W)
}
\stopformula
En particulier, nous obtenons que $\displaystyle\lim_{n‚Üí+‚àû}P_n(A)=B$
\stopList
\item\startList
\item Nous remarquons que 
\startformula
M^2=\Matrix{
\NC 0\NC 0\NC 1\NR
\NC 1\NC -3\NC 3\NR
\NC 3\NC -8\NC 6}\qquad\Et\qquad 
M^3=\Matrix{
\NC 1\NC -3\NC 3\NR
\NC 3\NC -8\NC 6\NR
\NC 6\NC -15\NC 10}
\stopformula
Alors, nous remarquons que 
\startformula
M^3-3M^2+3M-I_3=\Matrix{
\NC 1-1\NC -3+3\NC 3-3\NR
\NC 3-3\NC -8+9-1\NC 6-9+3\NR
\NC 6-9+3\NC -15+24-9\NC 10-18+9-1}=0
\stopformula
de sorte que le polyn√¥me unitaire $P=X^3-3X^2+3X-1$ est un polyn√¥me annulateur de $M$. 
\item Proc√©dons √† la division euclidienne (th√©orique) de $X^n$ par $P$. Alors, il existe deux polyn√¥mes $Q‚àà‚Ñù[X]$ et $P‚ààR_2[X]$ uniques tels que $X^n=PQ+R$.
{\it On veut surtout le reste de la division en fait...}

Comme $P=X^3-3X^2+3X-1=(X-1)^3$, en substituant $1$ √† $X$ puis en d√©rivant et en substituant $1$ √† $X$, puis en d√©rivant $2$ fois et en substituant $1$ √† $X$ dans 
\startformula
X^n=PQ+R=(X-1)^3Q+a+bX+cX^2,
\stopformula
il vient
\startformula
\System{
\NC a+b+c = 1\NR
\NC b+2c = n\NR
\NC 2c = n(n-1)
}‚ü∫ \System{
\NC c={n(n-1)\F 2}\NR
\NC b=n-n(n-1)=n(2-n)\NR
\NC a=1-b-c=1-{n(n-1)\F 2}-n(2-n)={n^2-3n+2\F 2}
}
\stopformula

En notant $R=a+bX+cX^2$ et en substituant $M$ √† $X$ il vient
\startformula
\Align{
\NC X^n\NC =P(M)Q(M)+R(M)=0+aI_3+bM+cM^2\NR
\NC\NC ={n^2-3n+2\F 2}I_3+n(2-n)M+{n(n-1)\F 2}M^2\qquad(n‚©æ1)
}
\stopformula
\item La suite $\big(P_n(M)\big)_{n‚©æ1}$ n'est pas convergente. {\it Prouvons le par l'absurde en essayant d'√©viter de souffrir}.
En effet, si elle √©tait convergente alors 
\startformula
(I_3-M)√óP_n(M)={1\F n}(1-M)‚àë_{k=0}^{n-1}M^k={1\F n}\Q(I_3-M^n\W)
\stopformula
le serait aussi et en particulier, la suite ${1\F n}M^n$ serait convergente, ce qui n'est clairement pas le cas, vu l'expression trouv√©e √† la question pr√©c√©dente.
\stopList
\item\startList
\item {\it Wow, des permutations maintenant et le symb√¥le de Kronecker...qui n'est pas expliqu√©, c'est mal...
\startformula
Œ¥_{i,j}=\System{
\NC 1 \NC \Si i=j\NR
\NC 0 \NC \Si i‚â†j}
\stopformula
Autrement dit, la matrice $A_œÉ$ a un $1$ par ligne. Sur la ligne $i$, le $1$ est situ√© sur la colonne de m√™me rang que $œÉ(i)$, l'image par $i$ de la permutation
}
\item Notons $A_œÉ=(a_{i,j})_{1‚©Ωi‚©Ωn\atop 1‚©Ωj‚©Ωn}$, $A_œÑ=(b_{i,j})_{1‚©Ωi‚©Ωn\atop 1‚©Ωj‚©Ωn}$ et $A_œÉA_œÑ=(c_{i,j})_{1‚©Ωi‚©Ωn\atop 1‚©Ωj‚©Ωn}$. Soit $i‚àà‚ü¶1,n‚üß$ et $j‚àà‚ü¶1,n‚üß$. D'apr√®s le cours, on a 
\startformula
\Align{
\NC c_{i,j}\NC \displaystyle=‚àë_{k=1}^na_{i,k}b_{k,j}=‚àë_{k=1}^n\underbrace{Œ¥_{i, œÉ(k)}Œ¥_{k,œÑ(j)}}_{\rlap{=0 \text{ si $i‚â†œÉ(k)$ ou $k‚â†œÑ(j)$ et $=1$ sinon}}}\NR
\NC\NC \displaystyle= Œ¥_{i, œÉ(œÉ^{-1}(i))}Œ¥_{œÉ^{-1}(i),œÑ(j)}=Œ¥_{œÉ^{-1}(i),œÑ(j)}=Œ¥_{i,œÉ(œÑ(j))}
}
\stopformula
(la seule valeur de $k$ pouvant donner autre chose que $0$ est $k=œÉ^{-1}(i)$ et on a √©galement $œÉ^{-1}(i)=œÑ(j) ‚ü∫i=œÉ(œÑ(j))$ ). En particulier, on obtient que la matrice $A_œÉA_œÑ$ a les m√™mes coefficients que la matrice $A_{œÉ‚àòœÑ}$, de sorte que 
\startformula
A_œÉA_œÑ=A_œÉ‚àòœÑ
\stopformula
{\it Pour info, les MP* font ce genre de question relativement souvent et ils en ont plusieurs comme cela √† tous leurs ds...
La, il valait mieux l'admettre peut √™tre ^^}
\item On a $A_{Id}=I_p$ (les $1$ sont tous sur la diagonale principale) et comme $A_œÉA_{œÉ^{-1}}=A_{œÉ‚àòœÉ^{-1}}=A_{Id}=I_p$, nous remarquons que la matrice $A_œÉ$ est inversible, d'inverse 
$A_{œÉ^{-1}}$. 
\item Il y a $p!$ permutations de $‚ü¶1,p‚üß$ et il y a donc autant de matrices de permutation
\item Comme il n'y a qu'un nombre fini de matrice de permutations et comme les matrices $(A_œÉ)^n=A_{œÉ^n}$ sont toutes des matrices de permutation pour $n‚©æ1$, il y en a au moins eux qui sont √©gales. autrement dit, 
il existe deux entiers distincts $p$ et $q$ tels que $(A_œÉ)^p=(A_œÉ)^q$. 
{\it Wow, on fait ce genre de raisonnement quand on fait de la th√©orie des groupes... √ßa a l'air fun fun la pr√©pa ECS √† st louis...}
\item Comme $(A_œÉ)^p=(A_œÉ)^q$ et comme ces matrice sont inversibles, on remarque que 
\startformula
(A_œÉ)^p\Q((A_œÉ)^q\W)^{-1}=I_r=(A_œÉ)^p(A_œÉ)^{-q}=(A_œÉ)^{p-q}
\stopformula
En particulier, il existe un entier $r=p-q‚â†0$ tel que $(A_œÉ)^r=I_p$
{\it en prenant pour $p$ le plus grand des deux entiers et pour $q$ le plus petit des entiers, on obtient √©galement que $r=q-p>0$ de sorte que $r‚©æ1$}
\item La suite $(A_œÉ)^n$ est $r$-p√©riodique car 
\startformula
(A_œÉ)^{n+r}=(A_œÉ)^n(A_œÉ)^r=(A_œÉ)^nI-r=(A_œÉ)^n\qquad(n‚©æ1)
\stopformula
\item {\it Bon, la je crois que l'auteur souhaite nous voir faire un raisonnement avec les matrices identique √† celui utilis√© pour obtenir le lemme au 1 (que l'on a jamais utilis√©).
Si on fait le parall√®le, la suite $(A_œÉ)^n$ est $r$-p√©riodique et donc $P_n(A_œÉ)$ est sens√© converger d'apr√®s le lemme vers $y={1\F n}‚àë_{k=0}^{r-1}(A_œÉ)^k$, etc...\crlf
bref, passons √† l'exercice
}
\stopList
\stopList


\centerline{Correction de l'exercice}

{\it Pr√©parons nous √† un festival de m√©thode MARRE}
\startList
\item Soit $k‚àà‚Ñï$.  
\startitemize[1]
\item Montrons que $N_k‚äÇN_{k+1}$. Soit $x‚ààN_k=\ker(f^k)$. Alors $f^k(x)=0$ de sorte que $f^{k+1}(x)=f\Q(f^k(x)\W)=f(0)=0$ et par cons√©quent $x‚àà\ker(f^{k+1})=N_{k+1}$. CQFD
\item Montrons que $I_{k+1}‚äÇI_k$. Soit $y‚ààI_{k+1}=\IM(f^{k+1})$. Alors il existe $x‚àà‚Ñù^n$ tel que $y=f^{k+1}(x)$ et alors, on remarque que $y=f^k(f(x))‚àà\IM(f^k)=I_k$. CQFD
\stopitemize 
\item Supposons qu'il n'existe pas d'entiers $p‚©Ωn$ tel que $N_p=N_{p+1}$. Alors la suite croissante de noyau $N_1‚äÇN_2‚äÇN_3‚äÇ‚ãØ‚äÇN_n‚äÇN_{n+1}$ est strictement croissante (aucun noyau n'est √©gale au suivant), de sorte qu'en pmrenant leur dimension, on obtient que 
\startformula
\dim(N_1)<\dim(N_2)<\dim(N_3)<‚ãØ<\dim(N_{n+1})
\stopformula
Mais alors, on obtient une suite strictement croissante de $n+1$ entiers de $‚ü¶0,n‚üß$. De sorte que $\dim(N_1)=0$, d'o√π $f$ est injective et donc bijective mais dans ce cas tous les noyaux $N_k$ valent $\{0\}$ et on a notre contradiction...
CQFD, il existe au moins un entier $p‚©Ωn$ tel que $N_p=N_{p+1}$.
{\it Il y a une id√©e importante √† retenir ici : quand une application $f$ a un noyau de dimension non nulle, les noyaux it√©r√©s de $f$ ont une dimension qui augmente strictement puis qui devient constante}
\item $I_{p+1}=I_p$ d'apr√®s a) Et il r√©sulte du th√©or√®me du rang que 
\startformula
\dim(I_{p+1})=\dim(‚Ñù^n)-\dim(N_{p+1})=\dim(‚Ñù^n)-\dim(N_p)=\dim(I_p)
\stopformula
Comme les noyaux ont m√™me dimension finie et l'un est inclus dans l'autre, on a $I_{p+1}=I_p$. 
\item Pour $k‚àà‚Ñï$, prouvons par r√©currence la proposition $\mc P_k:N_{p+k}=N_p$. 
\startitemize[1]
\item Les propositions $\mc P_0$ et $\mc P_1$ sont vraies d'apr√®s le r√©sultat de la question b 
\item Supposons la proposition $\mc P_k$ pour un entier $k‚©æ0$. 

Rappelons que $N_k‚äÇN_{p+k+1}$ (suite croissante de noyaux) et montrons maintenant que $N_{p+k+1}‚äÇN_p$.

Soit $x‚ààN_{p+k+1}=\ker(f^{p+k+1})$. alors, on a $0=f^{p+k+1}(x)=f^{p+k}\big(f(x)\big)$. A fortiori, $f(x)‚àà\ker(f^{p+k})=N_{p+k}=N_p=\ker(f^p)$ de sorte que 
\startformula
0=f^p\big(f(x)\big)=f^{p+1}(x).
\stopformula
En particulier $x‚àà\ker(f^{p+1})=N_{p+1}=N_p$. CQFD

En conclusion, $N_{p+k+1}‚äÇN_p$ et $N_p=N_{p+k+1}$ de sorte que la proposition $\mc P_{k+1}$ est vraie
\stopitemize
En conclusion, la proposition $\mc P_k$ est vraie pour $k‚àà‚Ñï$. 
\item On remarque que $N_p‚à©I_p=\{0\}$. En effet, si $y‚ààN_p‚à©I_p$, alors $f^p(y)=0$ et il existe un $x‚àà‚Ñù^n$ tel que $y=f^p(x)$ mais alors $0=f^p(y)=f^p(f^p(x))=f^{2p}(x)$
et donc $x‚ààN_{2p}=N_p$ de sorte que $y=f^p(x)=0$. .
En particulier, nous obtenons que $I_p‚äïN_p$. Par ailleurs, il r√©sulte du th√®or√®me du rang appliqu√© √† la fonction $f^p$ que 
$\dim(‚Ñù^n)=\dim\ker (f^p)+\dim(\IM(f^p)=\dim N_p+\dim I_p=\dim(N_p‚äïI_p)$.
Comme $I_p‚äïN_p‚äÇ‚Ñù^n$, il vient
\startformula
‚Ñù^n=I_p‚äïN_p
\stopformula
{\it magnifique...}

\stopList







\stoptext
\stopcomponent
\endinput
